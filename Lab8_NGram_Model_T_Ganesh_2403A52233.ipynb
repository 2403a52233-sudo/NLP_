{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOGfcfRKbpLd5S3vq3toHN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52233-sudo/NLP_/blob/main/Lab8_NGram_Model_T_Ganesh_2403A52233.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Corpus**"
      ],
      "metadata": {
        "id": "sy0mDvq8RK1A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jTpWKKtgP6te"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/professional_profile (1).csv\")\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "2hj0cWQ4Q5Fy",
        "outputId": "5c216273-5336-4ef5-8e74-21ec10fd4747"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          Description\n",
              "0                         I am working as a professor\n",
              "1                       I am working in SR University\n",
              "2                                I did my phd in NITW\n",
              "3                            I did my masters in OUCE\n",
              "4              I have 10 years of teaching experience\n",
              "5   I have published research papers in internatio...\n",
              "6      I have guided several PhD and Masters students\n",
              "7   My research interests include Artificial Intel...\n",
              "8   I have organized national and international co...\n",
              "9       I am a member of professional academic bodies\n",
              "10  I have secured funded research projects from g...\n",
              "11  I actively collaborate with international univ...\n",
              "12     I have received awards for academic excellence\n",
              "13  I regularly review research articles for reput...\n",
              "14  I have developed new curriculum for undergradu...\n",
              "15  I have supervised interdisciplinary research p...\n",
              "16  I conduct workshops and training programs for ...\n",
              "17   I have delivered keynote speeches at conferences\n",
              "18     I mentor students for competitive examinations\n",
              "19  I am involved in community outreach and extens...\n",
              "20           I have filed patents in my research area\n",
              "21   I have chaired technical sessions at conferences\n",
              "22   I serve on editorial boards of academic journals\n",
              "23      I contribute to research proposal evaluations\n",
              "24  I have established research laboratories in my...\n",
              "25     I guide students in industry-oriented projects\n",
              "26  I collaborate with industry partners for consu...\n",
              "27  I participate in curriculum accreditation proc...\n",
              "28  I have published book chapters with reputed pu...\n",
              "29  I am committed to innovative teaching methodol..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cb0d083-09a5-402f-8e26-2b4a7a280b77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am working as a professor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am working in SR University</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I did my phd in NITW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I did my masters in OUCE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have 10 years of teaching experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I have published research papers in internatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I have guided several PhD and Masters students</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>My research interests include Artificial Intel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I have organized national and international co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I am a member of professional academic bodies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I have secured funded research projects from g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I actively collaborate with international univ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I have received awards for academic excellence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I regularly review research articles for reput...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I have developed new curriculum for undergradu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I have supervised interdisciplinary research p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>I conduct workshops and training programs for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I have delivered keynote speeches at conferences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I mentor students for competitive examinations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I am involved in community outreach and extens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>I have filed patents in my research area</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>I have chaired technical sessions at conferences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>I serve on editorial boards of academic journals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I contribute to research proposal evaluations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>I have established research laboratories in my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>I guide students in industry-oriented projects</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>I collaborate with industry partners for consu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>I participate in curriculum accreditation proc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>I have published book chapters with reputed pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I am committed to innovative teaching methodol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cb0d083-09a5-402f-8e26-2b4a7a280b77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7cb0d083-09a5-402f-8e26-2b4a7a280b77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7cb0d083-09a5-402f-8e26-2b4a7a280b77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_576ce94d-fea8-4eba-a5de-faa6142349af\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_576ce94d-fea8-4eba-a5de-faa6142349af button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"I participate in curriculum accreditation processes\",\n          \"I have supervised interdisciplinary research projects\",\n          \"I contribute to research proposal evaluations\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uni Gram Counts**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eImUb986RMkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Combine the text from D1, D2, D3, D4\n",
        "combined_text = ' '.join(df['Description'].astype(str))\n",
        "\n",
        "# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "#Vocabulary size is length of unigrams\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82GNuswrRICS",
        "outputId": "bd60eb10-2201-4ba6-fe39-0a1fb3d9aa42"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "i: 29\n",
            "have: 13\n",
            "in: 9\n",
            "research: 8\n",
            "and: 6\n",
            "for: 6\n",
            "am: 5\n",
            "my: 5\n",
            "projects: 4\n",
            "of: 3\n",
            "international: 3\n",
            "journals: 3\n",
            "students: 3\n",
            "conferences: 3\n",
            "academic: 3\n",
            "with: 3\n",
            "working: 2\n",
            "a: 2\n",
            "did: 2\n",
            "phd: 2\n",
            "masters: 2\n",
            "teaching: 2\n",
            "published: 2\n",
            "collaborate: 2\n",
            "reputed: 2\n",
            "curriculum: 2\n",
            "programs: 2\n",
            "at: 2\n",
            "to: 2\n",
            "as: 1\n",
            "professor: 1\n",
            "sr: 1\n",
            "university: 1\n",
            "nitw: 1\n",
            "ouce: 1\n",
            "10: 1\n",
            "years: 1\n",
            "experience: 1\n",
            "papers: 1\n",
            "guided: 1\n",
            "several: 1\n",
            "interests: 1\n",
            "include: 1\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "machine: 1\n",
            "learning: 1\n",
            "organized: 1\n",
            "national: 1\n",
            "member: 1\n",
            "professional: 1\n",
            "bodies: 1\n",
            "secured: 1\n",
            "funded: 1\n",
            "from: 1\n",
            "government: 1\n",
            "agencies: 1\n",
            "actively: 1\n",
            "universities: 1\n",
            "received: 1\n",
            "awards: 1\n",
            "excellence: 1\n",
            "regularly: 1\n",
            "review: 1\n",
            "articles: 1\n",
            "developed: 1\n",
            "new: 1\n",
            "undergraduate: 1\n",
            "postgraduate: 1\n",
            "supervised: 1\n",
            "interdisciplinary: 1\n",
            "conduct: 1\n",
            "workshops: 1\n",
            "training: 1\n",
            "faculty: 1\n",
            "development: 1\n",
            "delivered: 1\n",
            "keynote: 1\n",
            "speeches: 1\n",
            "mentor: 1\n",
            "competitive: 1\n",
            "examinations: 1\n",
            "involved: 1\n",
            "community: 1\n",
            "outreach: 1\n",
            "extension: 1\n",
            "activities: 1\n",
            "filed: 1\n",
            "patents: 1\n",
            "area: 1\n",
            "chaired: 1\n",
            "technical: 1\n",
            "sessions: 1\n",
            "serve: 1\n",
            "on: 1\n",
            "editorial: 1\n",
            "boards: 1\n",
            "contribute: 1\n",
            "proposal: 1\n",
            "evaluations: 1\n",
            "established: 1\n",
            "laboratories: 1\n",
            "department: 1\n",
            "guide: 1\n",
            "industry-oriented: 1\n",
            "industry: 1\n",
            "partners: 1\n",
            "consultancy: 1\n",
            "participate: 1\n",
            "accreditation: 1\n",
            "processes: 1\n",
            "book: 1\n",
            "chapters: 1\n",
            "publishers: 1\n",
            "committed: 1\n",
            "innovative: 1\n",
            "methodologies: 1\n",
            "Vocabulary Size= 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "lS0y_KtpVujx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "# combined_text = f\"{D1} {D2} {D3} {D4}\" # This line caused the error\n",
        "# Use the already defined combined_text from the previous cell\n",
        "# If combined_text is not defined, you would define it here as:\n",
        "# combined_text = ' '.join(df['Description'].astype(str))\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Veq51l4eR0wQ",
        "outputId": "6e081041-2cba-440e-cb65-21d71129a0c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "i have: 13\n",
            "i am: 5\n",
            "journals i: 3\n",
            "conferences i: 3\n",
            "projects i: 3\n",
            "am working: 2\n",
            "i did: 2\n",
            "did my: 2\n",
            "have published: 2\n",
            "my research: 2\n",
            "research projects: 2\n",
            "collaborate with: 2\n",
            "at conferences: 2\n",
            "in my: 2\n",
            "working as: 1\n",
            "as a: 1\n",
            "a professor: 1\n",
            "professor i: 1\n",
            "working in: 1\n",
            "in sr: 1\n",
            "sr university: 1\n",
            "university i: 1\n",
            "my phd: 1\n",
            "phd in: 1\n",
            "in nitw: 1\n",
            "nitw i: 1\n",
            "my masters: 1\n",
            "masters in: 1\n",
            "in ouce: 1\n",
            "ouce i: 1\n",
            "have 10: 1\n",
            "10 years: 1\n",
            "years of: 1\n",
            "of teaching: 1\n",
            "teaching experience: 1\n",
            "experience i: 1\n",
            "published research: 1\n",
            "research papers: 1\n",
            "papers in: 1\n",
            "in international: 1\n",
            "international journals: 1\n",
            "have guided: 1\n",
            "guided several: 1\n",
            "several phd: 1\n",
            "phd and: 1\n",
            "and masters: 1\n",
            "masters students: 1\n",
            "students my: 1\n",
            "research interests: 1\n",
            "interests include: 1\n",
            "include artificial: 1\n",
            "artificial intelligence: 1\n",
            "intelligence and: 1\n",
            "and machine: 1\n",
            "machine learning: 1\n",
            "learning i: 1\n",
            "have organized: 1\n",
            "organized national: 1\n",
            "national and: 1\n",
            "and international: 1\n",
            "international conferences: 1\n",
            "am a: 1\n",
            "a member: 1\n",
            "member of: 1\n",
            "of professional: 1\n",
            "professional academic: 1\n",
            "academic bodies: 1\n",
            "bodies i: 1\n",
            "have secured: 1\n",
            "secured funded: 1\n",
            "funded research: 1\n",
            "projects from: 1\n",
            "from government: 1\n",
            "government agencies: 1\n",
            "agencies i: 1\n",
            "i actively: 1\n",
            "actively collaborate: 1\n",
            "with international: 1\n",
            "international universities: 1\n",
            "universities i: 1\n",
            "have received: 1\n",
            "received awards: 1\n",
            "awards for: 1\n",
            "for academic: 1\n",
            "academic excellence: 1\n",
            "excellence i: 1\n",
            "i regularly: 1\n",
            "regularly review: 1\n",
            "review research: 1\n",
            "research articles: 1\n",
            "articles for: 1\n",
            "for reputed: 1\n",
            "reputed journals: 1\n",
            "have developed: 1\n",
            "developed new: 1\n",
            "new curriculum: 1\n",
            "curriculum for: 1\n",
            "for undergraduate: 1\n",
            "undergraduate and: 1\n",
            "and postgraduate: 1\n",
            "postgraduate programs: 1\n",
            "programs i: 1\n",
            "have supervised: 1\n",
            "supervised interdisciplinary: 1\n",
            "interdisciplinary research: 1\n",
            "i conduct: 1\n",
            "conduct workshops: 1\n",
            "workshops and: 1\n",
            "and training: 1\n",
            "training programs: 1\n",
            "programs for: 1\n",
            "for faculty: 1\n",
            "faculty development: 1\n",
            "development i: 1\n",
            "have delivered: 1\n",
            "delivered keynote: 1\n",
            "keynote speeches: 1\n",
            "speeches at: 1\n",
            "i mentor: 1\n",
            "mentor students: 1\n",
            "students for: 1\n",
            "for competitive: 1\n",
            "competitive examinations: 1\n",
            "examinations i: 1\n",
            "am involved: 1\n",
            "involved in: 1\n",
            "in community: 1\n",
            "community outreach: 1\n",
            "outreach and: 1\n",
            "and extension: 1\n",
            "extension activities: 1\n",
            "activities i: 1\n",
            "have filed: 1\n",
            "filed patents: 1\n",
            "patents in: 1\n",
            "research area: 1\n",
            "area i: 1\n",
            "have chaired: 1\n",
            "chaired technical: 1\n",
            "technical sessions: 1\n",
            "sessions at: 1\n",
            "i serve: 1\n",
            "serve on: 1\n",
            "on editorial: 1\n",
            "editorial boards: 1\n",
            "boards of: 1\n",
            "of academic: 1\n",
            "academic journals: 1\n",
            "i contribute: 1\n",
            "contribute to: 1\n",
            "to research: 1\n",
            "research proposal: 1\n",
            "proposal evaluations: 1\n",
            "evaluations i: 1\n",
            "have established: 1\n",
            "established research: 1\n",
            "research laboratories: 1\n",
            "laboratories in: 1\n",
            "my department: 1\n",
            "department i: 1\n",
            "i guide: 1\n",
            "guide students: 1\n",
            "students in: 1\n",
            "in industry-oriented: 1\n",
            "industry-oriented projects: 1\n",
            "i collaborate: 1\n",
            "with industry: 1\n",
            "industry partners: 1\n",
            "partners for: 1\n",
            "for consultancy: 1\n",
            "consultancy projects: 1\n",
            "i participate: 1\n",
            "participate in: 1\n",
            "in curriculum: 1\n",
            "curriculum accreditation: 1\n",
            "accreditation processes: 1\n",
            "processes i: 1\n",
            "published book: 1\n",
            "book chapters: 1\n",
            "chapters with: 1\n",
            "with reputed: 1\n",
            "reputed publishers: 1\n",
            "publishers i: 1\n",
            "am committed: 1\n",
            "committed to: 1\n",
            "to innovative: 1\n",
            "innovative teaching: 1\n",
            "teaching methodologies: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "geXzUhZaSAlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "# combined_text = f\"{D1} {D2} {D3} {D4}\" # This line caused the error\n",
        "# Use the already defined combined_text from the previous cell\n",
        "# If combined_text is not defined, you would define it here as:\n",
        "# combined_text = ' '.join(df['Description'].astype(str))\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw8JuhhxR_Ej",
        "outputId": "977e4b1a-ab89-4a4d-e8a0-7b3697b8129e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "i am working: 2\n",
            "i did my: 2\n",
            "i have published: 2\n",
            "journals i have: 2\n",
            "at conferences i: 2\n",
            "am working as: 1\n",
            "working as a: 1\n",
            "as a professor: 1\n",
            "a professor i: 1\n",
            "professor i am: 1\n",
            "am working in: 1\n",
            "working in sr: 1\n",
            "in sr university: 1\n",
            "sr university i: 1\n",
            "university i did: 1\n",
            "did my phd: 1\n",
            "my phd in: 1\n",
            "phd in nitw: 1\n",
            "in nitw i: 1\n",
            "nitw i did: 1\n",
            "did my masters: 1\n",
            "my masters in: 1\n",
            "masters in ouce: 1\n",
            "in ouce i: 1\n",
            "ouce i have: 1\n",
            "i have 10: 1\n",
            "have 10 years: 1\n",
            "10 years of: 1\n",
            "years of teaching: 1\n",
            "of teaching experience: 1\n",
            "teaching experience i: 1\n",
            "experience i have: 1\n",
            "have published research: 1\n",
            "published research papers: 1\n",
            "research papers in: 1\n",
            "papers in international: 1\n",
            "in international journals: 1\n",
            "international journals i: 1\n",
            "i have guided: 1\n",
            "have guided several: 1\n",
            "guided several phd: 1\n",
            "several phd and: 1\n",
            "phd and masters: 1\n",
            "and masters students: 1\n",
            "masters students my: 1\n",
            "students my research: 1\n",
            "my research interests: 1\n",
            "research interests include: 1\n",
            "interests include artificial: 1\n",
            "include artificial intelligence: 1\n",
            "artificial intelligence and: 1\n",
            "intelligence and machine: 1\n",
            "and machine learning: 1\n",
            "machine learning i: 1\n",
            "learning i have: 1\n",
            "i have organized: 1\n",
            "have organized national: 1\n",
            "organized national and: 1\n",
            "national and international: 1\n",
            "and international conferences: 1\n",
            "international conferences i: 1\n",
            "conferences i am: 1\n",
            "i am a: 1\n",
            "am a member: 1\n",
            "a member of: 1\n",
            "member of professional: 1\n",
            "of professional academic: 1\n",
            "professional academic bodies: 1\n",
            "academic bodies i: 1\n",
            "bodies i have: 1\n",
            "i have secured: 1\n",
            "have secured funded: 1\n",
            "secured funded research: 1\n",
            "funded research projects: 1\n",
            "research projects from: 1\n",
            "projects from government: 1\n",
            "from government agencies: 1\n",
            "government agencies i: 1\n",
            "agencies i actively: 1\n",
            "i actively collaborate: 1\n",
            "actively collaborate with: 1\n",
            "collaborate with international: 1\n",
            "with international universities: 1\n",
            "international universities i: 1\n",
            "universities i have: 1\n",
            "i have received: 1\n",
            "have received awards: 1\n",
            "received awards for: 1\n",
            "awards for academic: 1\n",
            "for academic excellence: 1\n",
            "academic excellence i: 1\n",
            "excellence i regularly: 1\n",
            "i regularly review: 1\n",
            "regularly review research: 1\n",
            "review research articles: 1\n",
            "research articles for: 1\n",
            "articles for reputed: 1\n",
            "for reputed journals: 1\n",
            "reputed journals i: 1\n",
            "i have developed: 1\n",
            "have developed new: 1\n",
            "developed new curriculum: 1\n",
            "new curriculum for: 1\n",
            "curriculum for undergraduate: 1\n",
            "for undergraduate and: 1\n",
            "undergraduate and postgraduate: 1\n",
            "and postgraduate programs: 1\n",
            "postgraduate programs i: 1\n",
            "programs i have: 1\n",
            "i have supervised: 1\n",
            "have supervised interdisciplinary: 1\n",
            "supervised interdisciplinary research: 1\n",
            "interdisciplinary research projects: 1\n",
            "research projects i: 1\n",
            "projects i conduct: 1\n",
            "i conduct workshops: 1\n",
            "conduct workshops and: 1\n",
            "workshops and training: 1\n",
            "and training programs: 1\n",
            "training programs for: 1\n",
            "programs for faculty: 1\n",
            "for faculty development: 1\n",
            "faculty development i: 1\n",
            "development i have: 1\n",
            "i have delivered: 1\n",
            "have delivered keynote: 1\n",
            "delivered keynote speeches: 1\n",
            "keynote speeches at: 1\n",
            "speeches at conferences: 1\n",
            "conferences i mentor: 1\n",
            "i mentor students: 1\n",
            "mentor students for: 1\n",
            "students for competitive: 1\n",
            "for competitive examinations: 1\n",
            "competitive examinations i: 1\n",
            "examinations i am: 1\n",
            "i am involved: 1\n",
            "am involved in: 1\n",
            "involved in community: 1\n",
            "in community outreach: 1\n",
            "community outreach and: 1\n",
            "outreach and extension: 1\n",
            "and extension activities: 1\n",
            "extension activities i: 1\n",
            "activities i have: 1\n",
            "i have filed: 1\n",
            "have filed patents: 1\n",
            "filed patents in: 1\n",
            "patents in my: 1\n",
            "in my research: 1\n",
            "my research area: 1\n",
            "research area i: 1\n",
            "area i have: 1\n",
            "i have chaired: 1\n",
            "have chaired technical: 1\n",
            "chaired technical sessions: 1\n",
            "technical sessions at: 1\n",
            "sessions at conferences: 1\n",
            "conferences i serve: 1\n",
            "i serve on: 1\n",
            "serve on editorial: 1\n",
            "on editorial boards: 1\n",
            "editorial boards of: 1\n",
            "boards of academic: 1\n",
            "of academic journals: 1\n",
            "academic journals i: 1\n",
            "journals i contribute: 1\n",
            "i contribute to: 1\n",
            "contribute to research: 1\n",
            "to research proposal: 1\n",
            "research proposal evaluations: 1\n",
            "proposal evaluations i: 1\n",
            "evaluations i have: 1\n",
            "i have established: 1\n",
            "have established research: 1\n",
            "established research laboratories: 1\n",
            "research laboratories in: 1\n",
            "laboratories in my: 1\n",
            "in my department: 1\n",
            "my department i: 1\n",
            "department i guide: 1\n",
            "i guide students: 1\n",
            "guide students in: 1\n",
            "students in industry-oriented: 1\n",
            "in industry-oriented projects: 1\n",
            "industry-oriented projects i: 1\n",
            "projects i collaborate: 1\n",
            "i collaborate with: 1\n",
            "collaborate with industry: 1\n",
            "with industry partners: 1\n",
            "industry partners for: 1\n",
            "partners for consultancy: 1\n",
            "for consultancy projects: 1\n",
            "consultancy projects i: 1\n",
            "projects i participate: 1\n",
            "i participate in: 1\n",
            "participate in curriculum: 1\n",
            "in curriculum accreditation: 1\n",
            "curriculum accreditation processes: 1\n",
            "accreditation processes i: 1\n",
            "processes i have: 1\n",
            "have published book: 1\n",
            "published book chapters: 1\n",
            "book chapters with: 1\n",
            "chapters with reputed: 1\n",
            "with reputed publishers: 1\n",
            "reputed publishers i: 1\n",
            "publishers i am: 1\n",
            "i am committed: 1\n",
            "am committed to: 1\n",
            "committed to innovative: 1\n",
            "to innovative teaching: 1\n",
            "innovative teaching methodologies: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "3b9menmGSd_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD7qMAd7SnOn",
        "outputId": "a42a1920-cf29-423b-939b-26a1dea5bf3b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  working is  0.4\n",
            "probability of  a is  0.2\n",
            "probability of  involved is  0.2\n",
            "probability of  committed is  0.2\n",
            "Given sequence: 'I am', predicted next word: 'working'\n",
            "probability of  phd is  0.2\n",
            "probability of  masters is  0.2\n",
            "probability of  research is  0.4\n",
            "probability of  department is  0.2\n",
            "Given sequence: 'I did my', predicted next word: 'research'\n",
            "probability of  am is  0.1724137931034483\n",
            "probability of  did is  0.06896551724137931\n",
            "probability of  have is  0.4482758620689655\n",
            "probability of  actively is  0.034482758620689655\n",
            "probability of  regularly is  0.034482758620689655\n",
            "probability of  conduct is  0.034482758620689655\n",
            "probability of  mentor is  0.034482758620689655\n",
            "probability of  serve is  0.034482758620689655\n",
            "probability of  contribute is  0.034482758620689655\n",
            "probability of  guide is  0.034482758620689655\n",
            "probability of  collaborate is  0.034482758620689655\n",
            "probability of  participate is  0.034482758620689655\n",
            "Given sequence: 'professor I', predicted next word: 'have'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Bi-Gram Model**"
      ],
      "metadata": {
        "id": "qBl-eTA2TU2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEi4NifmTXj1",
        "outputId": "8e26c0ee-3cbe-4774-a6e5-6c8046fed8a5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of  working is  0.4\n",
            "probability of  a is  0.2\n",
            "probability of  involved is  0.2\n",
            "probability of  committed is  0.2\n",
            "Given sequence: 'i am', predicted next word: 'working'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "VE3G354oTcBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Nl4IXDTec0",
        "outputId": "8a9a2d14-bb12-4f97-c239-27fcd273fb16"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  as is  0.5\n",
            "probability of  in is  0.5\n",
            "Given sequence: 'I am working', predicted next word: 'as'\n",
            "probability of  phd is  0.5\n",
            "probability of  masters is  0.5\n",
            "Given sequence: 'I did my', predicted next word: 'phd'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Tri-Gram Model**"
      ],
      "metadata": {
        "id": "h9vQkgx2Tj61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgaxUbcpThI0",
        "outputId": "a86c9f99-c8f1-4f01-982f-45d7c5067bb2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am conducting\n",
            "Given sequence: 'i am conducting', predicted next word: 'No trigram found starting with 'am conducting'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ],
      "metadata": {
        "id": "M-B_aq8pTp4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tkh_J1JTqvJ",
        "outputId": "d0d427ca-434c-483b-f51e-d5cabfe7be5b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of working is  0.02459016393442623\n",
            "probability of a is  0.01639344262295082\n",
            "probability of involved is  0.01639344262295082\n",
            "probability of committed is  0.01639344262295082\n",
            "Given sequence: 'I am', predicted next word: 'working'\n",
            "probability of phd is  0.01639344262295082\n",
            "probability of masters is  0.01639344262295082\n",
            "probability of research is  0.02459016393442623\n",
            "probability of department is  0.01639344262295082\n",
            "Given sequence: 'I did my', predicted next word: 'research'\n",
            "probability of am is  0.0410958904109589\n",
            "probability of did is  0.02054794520547945\n",
            "probability of have is  0.0958904109589041\n",
            "probability of actively is  0.0136986301369863\n",
            "probability of regularly is  0.0136986301369863\n",
            "probability of conduct is  0.0136986301369863\n",
            "probability of mentor is  0.0136986301369863\n",
            "probability of serve is  0.0136986301369863\n",
            "probability of contribute is  0.0136986301369863\n",
            "probability of guide is  0.0136986301369863\n",
            "probability of collaborate is  0.0136986301369863\n",
            "probability of participate is  0.0136986301369863\n",
            "Given sequence: 'professor I', predicted next word: 'have'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "Iiky7VH0TxLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czO0w1jHTxl8",
        "outputId": "a004e74c-d85a-4412-ca8a-69e2899df6c5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti have\n",
            "probability of 10 is  0.015384615384615385\n",
            "probability of published is  0.023076923076923078\n",
            "probability of guided is  0.015384615384615385\n",
            "probability of organized is  0.015384615384615385\n",
            "probability of secured is  0.015384615384615385\n",
            "probability of received is  0.015384615384615385\n",
            "probability of developed is  0.015384615384615385\n",
            "probability of supervised is  0.015384615384615385\n",
            "probability of delivered is  0.015384615384615385\n",
            "probability of filed is  0.015384615384615385\n",
            "probability of chaired is  0.015384615384615385\n",
            "probability of established is  0.015384615384615385\n",
            "Given sequence: 'i have', predicted next word: 'published'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ],
      "metadata": {
        "id": "QeLMRSbqUElV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvmUNfmnUE8p",
        "outputId": "c641f51e-d7d9-4dce-e07b-0cfae4ff5d68"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  as is  0.01680672268907563\n",
            "probability of  in is  0.01680672268907563\n",
            "Given sequence: 'I am working', predicted next word: 'as'\n",
            "probability of  phd is  0.01680672268907563\n",
            "probability of  masters is  0.01680672268907563\n",
            "Given sequence: 'I did my', predicted next word: 'phd'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "Gs2lYMmCURqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1WGdzQjUaTz",
        "outputId": "c44dd074-a7b0-4f2e-e50d-a423002443d4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am going\n",
            "Given sequence: 'i am going', predicted next word: 'No trigram found starting with 'am going'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "y-dSg-zVUc4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0XJbNt9UfHQ",
        "outputId": "51c2675d-bea1-4d4d-a0d6-1336986b3383"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of working is  0.03937007874015748\n",
            "probability of a is  0.023622047244094488\n",
            "probability of involved is  0.023622047244094488\n",
            "probability of committed is  0.023622047244094488\n",
            "Given sequence: 'I am', predicted next word: 'working'\n",
            "probability of phd is  0.023622047244094488\n",
            "probability of masters is  0.023622047244094488\n",
            "probability of research is  0.03937007874015748\n",
            "probability of department is  0.023622047244094488\n",
            "Given sequence: 'I did my', predicted next word: 'research'\n",
            "probability of am is  0.06285714285714286\n",
            "probability of did is  0.02857142857142857\n",
            "probability of have is  0.15428571428571428\n",
            "probability of actively is  0.017142857142857144\n",
            "probability of regularly is  0.017142857142857144\n",
            "probability of conduct is  0.017142857142857144\n",
            "probability of mentor is  0.017142857142857144\n",
            "probability of serve is  0.017142857142857144\n",
            "probability of contribute is  0.017142857142857144\n",
            "probability of guide is  0.017142857142857144\n",
            "probability of collaborate is  0.017142857142857144\n",
            "probability of participate is  0.017142857142857144\n",
            "Given sequence: 'professor I', predicted next word: 'have'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "vWmH2nkwUxgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZtDCbZ-UyWE",
        "outputId": "7699c237-e17c-4ad6-bc99-d2363c9f5b37"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "probability of working is  0.03937007874015748\n",
            "probability of a is  0.023622047244094488\n",
            "probability of involved is  0.023622047244094488\n",
            "probability of committed is  0.023622047244094488\n",
            "Given sequence: 'i am', predicted next word: 'working'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "VgrnTCDVU03X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN0cFqmgU3an",
        "outputId": "20d9a275-33b0-4e7b-c556-08ed072e4432"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  as is  0.024793388429752067\n",
            "probability of  in is  0.024793388429752067\n",
            "Given sequence: 'I am working', predicted next word: 'as'\n",
            "probability of  phd is  0.024793388429752067\n",
            "probability of  masters is  0.024793388429752067\n",
            "Given sequence: 'I did my', predicted next word: 'phd'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "_TDoQRKOVGmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeawtUr6VI1O",
        "outputId": "a6cf78fc-c3c4-485d-afe8-c7542538deaa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am working\n",
            "probability of  as is  0.024793388429752067\n",
            "probability of  in is  0.024793388429752067\n",
            "Given sequence: 'i am working', predicted next word: 'as'\n"
          ]
        }
      ]
    }
  ]
}